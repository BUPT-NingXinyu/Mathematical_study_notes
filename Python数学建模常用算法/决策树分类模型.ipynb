{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c0d85fd-4871-4e21-9e45-14d697c0b80a",
   "metadata": {},
   "source": [
    "# 决策树分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b28c8-e43b-4df5-91c8-0c6cfa28ff61",
   "metadata": {},
   "source": [
    "这个监督式学习算法通常被用于分类问题。令人惊奇的是，它同时适用于分类变量和连续因变量。在这个算法中，我们将总体分成两个或更多的同类群。这是根据最重要的属性或者自变量来分成尽可能不同的组别。想要知道更多，可以阅读：简化决策树。http://www.analyticsvidhya.com/blog/2015/01/decision-tree-simplified/\n",
    "\n",
    "![](./img/DecisionTree1.jpg)\n",
    "\n",
    "在上图中你可以看到，根据多种属性，人群被分成了不同的四个小组，来判断 “他们会不会去玩”。为了把总体分成不同组别，需要用到许多技术，比如说 Gini、Information Gain、Chi-square、entropy。\n",
    "\n",
    "理解决策树工作机制的最好方式是玩Jezzball，一个微软的经典游戏(见下图)。这个游戏的最终目的，是在一个可以移动墙壁的房间里，通过造墙来分割出没有小球的、尽量大的空间。\n",
    "\n",
    "![](./img/DecisionTree2.jpg)\n",
    "\n",
    "因此，每一次你用墙壁来分隔房间时，都是在尝试着在同一间房里创建两个不同的总体。相似地，决策树也在把总体尽量分割到不同的组里去。\n",
    "\n",
    "来源：https://blog.csdn.net/troubleshooter/article/details/117298665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0a74db-16f3-4b0e-b2dc-48937b7825fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Import Library#Import other necessary libraries like pandas, numpy...\n",
    "\n",
    "from sklearn import tree  #Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "\n",
    "# 这里我们使用 K-means聚类模型中示例的明显 2 分类的 20 个点作为数据集, 将 K-means聚类结果 result 作为决策树的训练标签 by JayceTalis\n",
    "import numpy as np\n",
    "c1x=np.random.uniform(0.5,1.5,(1,10))\n",
    "c1y=np.random.uniform(0.5,1.5,(1,10))\n",
    "c2x=np.random.uniform(3.5,4.5,(1,10))\n",
    "c2y=np.random.uniform(3.5,4.5,(1,10))\n",
    "x=np.hstack((c1x,c2x))\n",
    "y=np.hstack((c2y,c2y))\n",
    "X=np.vstack((x,y)).T\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    " \n",
    "kemans=KMeans(n_clusters=2)\n",
    "result=kemans.fit_predict(X) #训练及预测\n",
    "# print(result)   #分类结果\n",
    "\n",
    "#Create tree object\n",
    "#for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini\n",
    "model=tree.DecisionTreeClassifier(criterion='gini')  \n",
    "\n",
    "# model = tree.DecisionTreeRegressor() forregression# Train the model using the training sets andcheck score\n",
    "\n",
    "model.fit(X,result)\n",
    "\n",
    "model.score(X,result)#Predict\n",
    "\n",
    "predicted=model.predict(X)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320fa87-7a7b-49a7-85a3-52a6929008d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
